{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "002-ji-predictions-using-cloveai-base.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQO5LkaozGTg"
      },
      "source": [
        "#  Package preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OreYCVZ-oBny"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCJwU9s3mRhs",
        "outputId": "0c731fd7-0196-43c5-e10b-963b0de22d89"
      },
      "source": [
        "!pip3 install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 27kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3QAn57xvbSM",
        "outputId": "7c421297-e6e4-413c-cabb-9cd1d8bbf2e9"
      },
      "source": [
        "pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 23.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 28.9MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 81kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 92kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 122kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 133kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 153kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 163kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 174kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 184kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 194kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 204kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 215kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 225kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 235kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 16.2MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yexptVNzMfe"
      },
      "source": [
        "# Environment setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRhQwaYuoEHy",
        "outputId": "d7c9f487-1ef0-4294-eeb7-f15ac179079e"
      },
      "source": [
        "# Standard libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import sys\n",
        "from os.path import exists, join, basename, splitext\n",
        "import glob\n",
        "import numpy as np\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from ast import literal_eval as make_tuple\n",
        "from tqdm import tqdm\n",
        "from joblib import Parallel, delayed \n",
        "import codecs\n",
        "import argparse\n",
        "import unicodedata\n",
        "import unidecode\n",
        "import editdistance\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# Keras ocr\n",
        "#import keras_ocr\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "1K22dUe4nofS",
        "outputId": "e0806b50-5644-4eb2-d23d-c7b0c9628afe"
      },
      "source": [
        "'''%cd /content/\n",
        "git_repo_url = 'https://github.com/jandziak/deep-text-recognition-benchmark.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "project_name = project_name + '-pol'\n",
        "if not exists(project_name):\n",
        "  !git clone -q {git_repo_url} deep-text-recognition-benchmark-pol\n",
        "  !cd {project_name}\n",
        "  \n",
        "\n",
        "sys.path.append(project_name)\n",
        "from utils import CTCLabelConverter, CTCLabelConverterForBaiduWarpctc, AttnLabelConverter, Averager\n",
        "from dataset import hierarchical_dataset, AlignCollate, Batch_Balanced_Dataset,RawDataset\n",
        "from model import Model'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"%cd /content/\\ngit_repo_url = 'https://github.com/jandziak/deep-text-recognition-benchmark.git'\\nproject_name = splitext(basename(git_repo_url))[0]\\nproject_name = project_name + '-pol'\\nif not exists(project_name):\\n  !git clone -q {git_repo_url} deep-text-recognition-benchmark-pol\\n  !cd {project_name}\\n  \\n\\nsys.path.append(project_name)\\nfrom utils import CTCLabelConverter, CTCLabelConverterForBaiduWarpctc, AttnLabelConverter, Averager\\nfrom dataset import hierarchical_dataset, AlignCollate, Batch_Balanced_Dataset,RawDataset\\nfrom model import Model\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59FMymt1_5vU"
      },
      "source": [
        "git_repo_url = 'https://github.com/clovaai/deep-text-recognition-benchmark.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "project_name = project_name \n",
        "if not exists(project_name):\n",
        "  !git clone -q {git_repo_url} \n",
        "  !cd {project_name}\n",
        "sys.path.append(project_name)\n",
        "from utils import CTCLabelConverter, CTCLabelConverterForBaiduWarpctc, AttnLabelConverter, Averager\n",
        "from dataset import hierarchical_dataset, AlignCollate, Batch_Balanced_Dataset,RawDataset\n",
        "from model import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVxcd-Pnor35",
        "outputId": "c1c92ae8-685f-446b-d36c-607cdc51b12d"
      },
      "source": [
        "%cd /content/\n",
        "git_repo_url = 'https://github.com/githubharald/CTCWordBeamSearch.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "\n",
        "if not exists(project_name):\n",
        "  !git clone -q {git_repo_url}\n",
        "  %cd {project_name}\n",
        "  !pip install .\n",
        "\n",
        "from word_beam_search import WordBeamSearch\n",
        "\n",
        "def wbs_decode(feedMat, corpus, chars, wordChars):\n",
        "    \"decode using word beam search. Result is tuple, first entry is label string, second entry is char string.\"\n",
        "\n",
        "    # decode using the \"Words\" mode of word beam search with beam width set to 25 and add-k smoothing to 0.0\n",
        "    assert len(chars) + 1 == feedMat.shape[2]\n",
        "    wbs = WordBeamSearch(25, 'Words', 0.0, corpus.encode('utf8'), chars.encode('utf8'), wordChars.encode('utf8'))\n",
        "    res = wbs.compute(feedMat)\n",
        "\n",
        "    # result is string of labels terminated by blank (similar to C-strings) if shorter than T\n",
        "    blank = len(chars)\n",
        "    s = ''\n",
        "\n",
        "    for label in res[0]:\n",
        "        if label == blank:\n",
        "            break\n",
        "        s += chars[label]  # map label to char\n",
        "    return res[0], s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/CTCWordBeamSearch\n",
            "Processing /content/CTCWordBeamSearch\n",
            "Building wheels for collected packages: word-beam-search\n",
            "  Building wheel for word-beam-search (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word-beam-search: filename=word_beam_search-1.0.0-cp36-cp36m-linux_x86_64.whl size=1177461 sha256=98ad3171fe3f7a90e25f66d7e84d0441505330e6fc30821f98b837a8540ac5fd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0qsn3g75/wheels/a9/69/4c/9d6acbecc7bf4b47c5072b213d9b08e4b9c43864bbed5206cc\n",
            "Successfully built word-beam-search\n",
            "Installing collected packages: word-beam-search\n",
            "Successfully installed word-beam-search-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmvnyjl0oQdg"
      },
      "source": [
        "def cut_top_part_image(image_name, input_folder, output_folder, cut_top): \n",
        "    in_path = input_folder + image_name\n",
        "    out_path = output_folder + image_name\n",
        "    image = cv2.imread(in_path)\n",
        "    cv2.imwrite(out_path, image[:cut_top,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfqqtwJkoRJA"
      },
      "source": [
        "def create_full_corpus(words):\n",
        "  return ' '.join(words.word.values)\n",
        "\n",
        "def create_corpus(filename, words, link_dict): \n",
        "  filename = filename.replace('__', '_')\n",
        "  filename = '_'.join(filename.split('_')[:-1])\n",
        "  res = link_dict[unicodedata.normalize('NFC', filename)]\n",
        "  res = [i for i, v in enumerate(list(words.word.values)) if v == res[0] or v == res[1]]\n",
        "  if len(res) == 1:\n",
        "    corpus = words.word.values[res[0]]\n",
        "  else: \n",
        "    corpus = ' '.join(words.word.values[res[0]:res[1]+2])\n",
        "  return corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySbavzCfoT87"
      },
      "source": [
        "def warpBox(image,\n",
        "            box,\n",
        "            target_height=None,\n",
        "            target_width=None,\n",
        "            margin=0,\n",
        "            cval=None,\n",
        "            return_transform=False,\n",
        "            skip_rotate=False):\n",
        "    \"\"\"Warp a boxed region in an image given by a set of four points into\n",
        "    a rectangle with a specified width and height. Useful for taking crops\n",
        "    of distorted or rotated text.\n",
        "    Args:\n",
        "        image: The image from which to take the box\n",
        "        box: A list of four points starting in the top left\n",
        "            corner and moving clockwise.\n",
        "        target_height: The height of the output rectangle\n",
        "        target_width: The width of the output rectangle\n",
        "        return_transform: Whether to return the transformation\n",
        "            matrix with the image.\n",
        "    \"\"\"\n",
        "    if cval is None:\n",
        "        cval = (0, 0, 0) if len(image.shape) == 3 else 0\n",
        "    if not skip_rotate:\n",
        "        box, _ = keras_ocr.tools.get_rotated_box(box)\n",
        "    w, h = keras_ocr.tools.get_rotated_width_height(box)\n",
        "    margin = h*margin\n",
        "    assert (\n",
        "        (target_width is None and target_height is None)\n",
        "        or (target_width is not None and target_height is not None)), \\\n",
        "            'Either both or neither of target width and height must be provided.'\n",
        "    if target_width is None and target_height is None:\n",
        "        target_width = w\n",
        "        target_height = h\n",
        "    scale = min(target_width / w, target_height / h)\n",
        "    M = cv2.getPerspectiveTransform(src=box,\n",
        "                                    dst=np.array([[margin, margin], [scale * w - margin, margin],\n",
        "                                                  [scale * w - margin, scale * h - margin],\n",
        "                                                  [margin, scale * h - margin]]).astype('float32'))\n",
        "    crop = cv2.warpPerspective(image, M, dsize=(int(scale * w), int(scale * h)))\n",
        "    target_shape = (target_height, target_width, 3) if len(image.shape) == 3 else (target_height,\n",
        "                                                                                   target_width)\n",
        "    full = (np.zeros(target_shape) + cval).astype('uint8')\n",
        "    full[:crop.shape[0], :crop.shape[1]] = crop\n",
        "    if return_transform:\n",
        "        return full, M\n",
        "    return full\n",
        "def calc_box(img_path, detector):\n",
        "    low_text_options = [0.3, 0.2, 0.1, 0.05, 0.01, 0.001, 0]\n",
        "    low_text_index = 0\n",
        "    img = keras_ocr.tools.read(img_path)\n",
        "    image = keras_ocr.detection.compute_input(img)\n",
        "    bboxes = keras_ocr.detection.getBoxes(detector.model.predict(np.array([image])), \n",
        "                                         text_threshold=0.9)\n",
        "\n",
        "    while bboxes[0].shape[0]>1:\n",
        "        bboxes = keras_ocr.detection.getBoxes(detector.model.predict(np.array([image])), \n",
        "                                             text_threshold=low_text_options[low_text_index])\n",
        "        low_text_index +=1\n",
        "    return bboxes, img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeRDe7A8ycqO"
      },
      "source": [
        "def prepare_corpus_tools(links_path, words_path): \n",
        "  ''' Function preparating the word lists and word ranges for constrained wbs'''\n",
        "  links = pd.read_csv(links_path)\n",
        "  words = pd.read_csv(words_path)\n",
        "  words['word'] = [remove_polish_letters(x) for x in words.word]\n",
        "  words.groupby('word').count().reset_index()\n",
        "  links = links[['0','1','2','3']]\n",
        "  links.columns = ['link_part', 'range', 'start', 'end']\n",
        "  links['start'] = [remove_polish_letters(x) for x in links['start']]\n",
        "  links['end'] = [remove_polish_letters(x) for x in links['end']] \n",
        "  \n",
        "  link_dict ={}\n",
        "  for i in range(len(links)):\n",
        "    link_dict[links.iloc[i]['link_part']] = (links.iloc[i]['start'],\n",
        "                                             links.iloc[i]['end'] )\n",
        "  return link_dict, words\n",
        "\n",
        "def remove_polish_letters(x):\n",
        "  return unidecode.unidecode(x)\n",
        "remove_polish_letters('óąćęłńśźż')\n",
        "\n",
        "def parse_model_arguments(model_path, character):\n",
        "  ''' Function that parses simple model arguments for the inference '''\n",
        "  parser = argparse.Namespace()\n",
        "  parser.eval_data=True\n",
        "  parser.benchmark_all_eval=False\n",
        "  parser.workers=4\n",
        "  parser.batch_size=1\n",
        "  parser.saved_model=model_path\n",
        "  parser.batch_max_length=1\n",
        "  parser.imgH=32\n",
        "  parser.imgW=100\n",
        "  parser.rgb=False\n",
        "  parser.character=character\n",
        "  parser.sensitive=False\n",
        "  parser.PAD=False\n",
        "  parser.Transformation='TPS'\n",
        "  parser.FeatureExtraction='ResNet'\n",
        "  parser.SequenceModeling='BiLSTM'\n",
        "  parser.Prediction='CTC'\n",
        "  parser.num_fiducial=20\n",
        "  parser.input_channel=1\n",
        "  parser.output_channel=512\n",
        "  parser.hidden_size=256\n",
        "  parser.num_gpu=0\n",
        "\n",
        "  opt = parser\n",
        "\n",
        "  opt.num_gpu = torch.cuda.device_count()\n",
        "  return opt\n",
        "\n",
        "def create_model(opt, device, converter):\n",
        "  opt.num_class = len(converter.character)\n",
        "\n",
        "\n",
        "  model = Model(opt)\n",
        "  model = torch.nn.DataParallel(model).to(device)\n",
        "\n",
        "  model.load_state_dict(torch.load(opt.saved_model, map_location=torch.device('cuda')))\n",
        "  model.eval()\n",
        "  print(\"model ready\")\n",
        "  return model\n",
        "\n",
        "def create_dataloader(data_path, opt):\n",
        "  AlignCollate_demo = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD)\n",
        "  demo_data = RawDataset(root=data_path, opt=opt)  # use RawDataset\n",
        "  demo_loader = torch.utils.data.DataLoader(\n",
        "      demo_data, batch_size=opt.batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=int(opt.workers),\n",
        "      collate_fn=AlignCollate_demo, pin_memory=True)\n",
        "  return demo_loader\n",
        "\n",
        "def decode_prediction(preds, preds_str, image_path_list, words, link_dict, \n",
        "                      corpus_full, character):\n",
        "  preds_np = preds.cpu().numpy()\n",
        "  x = np.array([np.array([np.append(x[1:], x[0])]) for x in preds_np[0]])\n",
        "  image_name = image_path_list[0].split('/')[-1]\n",
        "  corpus = create_corpus(image_name, words, link_dict)\n",
        "\n",
        "  res1 = wbs_decode(x, corpus, character, character)\n",
        "  res2 = wbs_decode(x, corpus_full, character, character)\n",
        "\n",
        "  temp_res = (f'{image_name}', res1[1], res2[1], preds_str[0], round(float(confidence_score.cpu().numpy()),4))\n",
        "\n",
        "  return temp_res\n",
        "  \n",
        "def decode_prediction1(image_path_list, words, link_dict):\n",
        "  image_name = image_path_list[0].split('/')[-1]\n",
        "  corpus = create_corpus(image_name, words, link_dict)\n",
        "\n",
        "  temp_res = (f'{image_name}', 1, 1, 1, 1)\n",
        "\n",
        "  return temp_res\n",
        "  \n",
        "def predict(image, model, batch_size, device, opt, converter):\n",
        "  length_for_pred = torch.IntTensor([opt.batch_max_length] * batch_size).to(device)\n",
        "  text_for_pred = torch.LongTensor(batch_size, opt.batch_max_length + 1).fill_(0).to(device)\n",
        "  preds = model(image, text_for_pred)\n",
        "  preds_prob = F.softmax(preds, dim=2)\n",
        "  preds_max_prob, _ = preds_prob.max(dim=2)\n",
        "  confidence_score = preds_max_prob[0].cumprod(dim=0)[-1]\n",
        "  preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
        "  _, preds_index = preds.max(2)\n",
        "  preds_str = converter.decode(preds_index, preds_size)\n",
        "  return preds, preds_str, confidence_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sQsuCmBBOGP"
      },
      "source": [
        "\n",
        "def calculate_levenshtein_score(s: str, t: str) -> float:\n",
        "    return editdistance.eval(s, t) / max(len(s), len(t))\n",
        "\n",
        "def evaluate_predicrtions(act, pred):\n",
        "    match = [x==y for x,y in zip(act, pred)]\n",
        "    accuracy = sum(match)/len(match)\n",
        "\n",
        "    edit = [editdistance.eval(x, y) for x,y in zip(act, pred)]\n",
        "    edit_distance = sum(edit)/len(edit)\n",
        "\n",
        "    normalised_edit = [calculate_levenshtein_score(x, y) for x,y in zip(act, \n",
        "                                                                        pred)]\n",
        "    normalised_edit_distance = sum(normalised_edit)/len(normalised_edit)                                                                  \n",
        "    \n",
        "    return accuracy, edit_distance, normalised_edit_distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNfyqsgOzeNT"
      },
      "source": [
        "# Pipeline parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZC8WS6Dzc9e"
      },
      "source": [
        "character=\"0123456789abcdefghijklmnoprstuwyzóąćęłńśźż\"\n",
        "character=\"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
        "cudnn.benchmark = True\n",
        "cudnn.deterministic = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ltJjzMjxF0v"
      },
      "source": [
        "#Preparation of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiNWFzFUpExC",
        "outputId": "53732270-a872-4087-91e0-0c96f413dad3"
      },
      "source": [
        "%cd /content\n",
        "!gdown --id 1GWlf5bVi0pCM8Ixyqza6TJlMtA836eq9\n",
        "!gdown --id 1PFKI761GLTuZYFV2vGuv4MAblNJQlKzI\n",
        "\n",
        "link_dict, words = prepare_corpus_tools(links_path='/content/link_to_range100k.csv',\n",
        "                                         words_path='/content/words_in_order.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GWlf5bVi0pCM8Ixyqza6TJlMtA836eq9\n",
            "To: /content/link_to_range100k.csv\n",
            "100% 43.8k/43.8k [00:00<00:00, 65.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PFKI761GLTuZYFV2vGuv4MAblNJQlKzI\n",
            "To: /content/words_in_order.csv\n",
            "100% 1.62M/1.62M [00:00<00:00, 25.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldOlrrjMyh8M"
      },
      "source": [
        "# Prepare model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTC52fJZpNDg",
        "outputId": "c202fc4c-1642-4086-fd63-25a87ee19161"
      },
      "source": [
        "!gdown --id 1FocnxQzFBIjDT2F9BkNUiLdo1cC3eaO0\n",
        "!gdown --id 1o8GYwkDWJ_hE76C9z4iyh0GfBLf45jTK"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1FocnxQzFBIjDT2F9BkNUiLdo1cC3eaO0\n",
            "To: /content/TPS-ResNet-BiLSTM-CTC.pth\n",
            "196MB [00:01, 129MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1o8GYwkDWJ_hE76C9z4iyh0GfBLf45jTK\n",
            "To: /content/best_accuracy.pth\n",
            "196MB [00:01, 125MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnmbKhkAob3c",
        "outputId": "398005e4-5b7e-468c-aee1-65bed3c304f9"
      },
      "source": [
        "opt = parse_model_arguments(model_path='/content/best_accuracy.pth', \n",
        "                      character=character)\n",
        "opt = parse_model_arguments(model_path='/content/TPS-ResNet-BiLSTM-CTC.pth', \n",
        "                      character=character)\n",
        "converter = CTCLabelConverter(opt.character)\n",
        "model = create_model(opt, device, converter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model ready\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJdrQ_YU2IpK",
        "outputId": "5a558812-c452-466b-89ba-b1d9ae64091b"
      },
      "source": [
        "%cd /content\n",
        "!mkdir data\n",
        "!gdown --id 1Fz7MdKwV1MtL6Eh5HUNh9lAoVW1O5CqA \n",
        "!gdown --id 1IyoszVzyR9GzVQAGobcuR2EDMzZPv309\n",
        "!unzip -q new_dataset.zip -d data\n",
        "\n",
        "data = pd.read_csv('predictions_output_ver2.csv')\n",
        "data['file_name_nfd'] = [unicodedata.normalize('NFD', file_name) \\\n",
        "  for file_name in data['file_name']]\n",
        "# Sanity check to see if we can map files from the system to the results in the \n",
        "# pandas Data Frame\n",
        "# len([file_name for file_name in os.listdir('data/new_dataset') \\\n",
        "#     if file_name in data['file_name_nfd'].values])\n",
        "#data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Fz7MdKwV1MtL6Eh5HUNh9lAoVW1O5CqA\n",
            "To: /content/predictions_output_ver2.csv\n",
            "2.72MB [00:00, 43.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IyoszVzyR9GzVQAGobcuR2EDMzZPv309\n",
            "To: /content/new_dataset.zip\n",
            "288MB [00:02, 135MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAHP0s0_2l2i",
        "outputId": "ad19a123-3b69-4b8e-896a-c6429dbf7c5b"
      },
      "source": [
        "%cd /content\n",
        "corpus_full = create_full_corpus(words)\n",
        "resss= []\n",
        "errors_list = {}\n",
        "demo_loader = create_dataloader(data_path='data/new_dataset/', opt=opt)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for image_tensors, image_path_list in tqdm(demo_loader):\n",
        "    batch_size = image_tensors.size(0)\n",
        "    image = image_tensors.to(device)\n",
        "    try:\n",
        "\n",
        "      # predict\n",
        "      preds, preds_str, confidence_score = predict(image, model, batch_size, \n",
        "                                                   device, opt, converter)\n",
        "                                                   \n",
        "      # postprocess\n",
        "      temp_res = decode_prediction(preds, preds_str, image_path_list, words, link_dict, \n",
        "                                   corpus_full, character )\n",
        "      resss.append(temp_res)\n",
        "    except: \n",
        "      errors_list[image_path_list[0]] = 1\n",
        "    \n",
        "#resss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19999/19999 [1:43:14<00:00,  3.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7fomDHGTD24",
        "outputId": "2859c906-365f-438b-a199-12cab25400d4"
      },
      "source": [
        "!gdown --id 1ZoMRbML-4x9d5_uonQ3DuwGoBqsvuuoH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZoMRbML-4x9d5_uonQ3DuwGoBqsvuuoH\n",
            "To: /content/17th_century_labels.csv\n",
            "\r  0% 0.00/898k [00:00<?, ?B/s]\r100% 898k/898k [00:00<00:00, 14.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As442WYwSpJW",
        "outputId": "0cef0d6c-8749-478f-f154-c615bacea312"
      },
      "source": [
        "data = pd.read_csv('17th_century_labels.csv')\n",
        "data['file_name_nfd'] = [unicodedata.normalize('NFD', file_name) \\\n",
        "  for file_name in data['file_name']]\n",
        "print(len(resss))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "R3xhS__TTm78",
        "outputId": "5b688900-096c-4343-fcc9-0590e826e996"
      },
      "source": [
        "resss1 = pd.DataFrame(resss)\n",
        "resss1.columns = ['file_name_nfd', 'wbs', 'wbs_full', 'model', 'conf']\n",
        "data = data.merge(resss1, on='file_name_nfd', how = 'left')\n",
        "data.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>label</th>\n",
              "      <th>file_name_nfd</th>\n",
              "      <th>wbs</th>\n",
              "      <th>wbs_full</th>\n",
              "      <th>model</th>\n",
              "      <th>conf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HistJezXVIIw_Rozmyślać się-Rozrysować się_123.jpg</td>\n",
              "      <td>rozmyślnie</td>\n",
              "      <td>HistJezXVIIw_Rozmyślać się-Rozrysować się...</td>\n",
              "      <td>rozpustnosc</td>\n",
              "      <td>urzadzenie</td>\n",
              "      <td>rozmysinte</td>\n",
              "      <td>0.3144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HistJezXVIIw_Rozmyślać się-Rozrysować się_136.jpg</td>\n",
              "      <td>rozmyślny</td>\n",
              "      <td>HistJezXVIIw_Rozmyślać się-Rozrysować się...</td>\n",
              "      <td>rozniosly</td>\n",
              "      <td>upokorzajacysie</td>\n",
              "      <td>rozmysiny</td>\n",
              "      <td>0.4078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HistJezXVIIw_Rozmyślać się-Rozrysować się_254.jpg</td>\n",
              "      <td>roznosić</td>\n",
              "      <td>HistJezXVIIw_Rozmyślać się-Rozrysować się...</td>\n",
              "      <td>rozproscicsie</td>\n",
              "      <td>wrzesniowy</td>\n",
              "      <td>roznosic</td>\n",
              "      <td>0.7182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HistJezXVIIw_Rozmyślać się-Rozrysować się_293.jpg</td>\n",
              "      <td>roznosić</td>\n",
              "      <td>HistJezXVIIw_Rozmyślać się-Rozrysować się...</td>\n",
              "      <td>rozrutny</td>\n",
              "      <td>zdrzodelny</td>\n",
              "      <td>roznosic</td>\n",
              "      <td>0.3443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HistJezXVIIw_Rozmyślać się-Rozrysować się_320.jpg</td>\n",
              "      <td>rozokowatość</td>\n",
              "      <td>HistJezXVIIw_Rozmyślać się-Rozrysować się...</td>\n",
              "      <td>rozrost</td>\n",
              "      <td>obmaczowac</td>\n",
              "      <td>rozokowaiost</td>\n",
              "      <td>0.0325</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           file_name  ...    conf\n",
              "0  HistJezXVIIw_Rozmyślać się-Rozrysować się_123.jpg  ...  0.3144\n",
              "1  HistJezXVIIw_Rozmyślać się-Rozrysować się_136.jpg  ...  0.4078\n",
              "2  HistJezXVIIw_Rozmyślać się-Rozrysować się_254.jpg  ...  0.7182\n",
              "3  HistJezXVIIw_Rozmyślać się-Rozrysować się_293.jpg  ...  0.3443\n",
              "4  HistJezXVIIw_Rozmyślać się-Rozrysować się_320.jpg  ...  0.0325\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9n0ubue_pXc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e77e5f-165e-41dd-e045-48ea9507ae8f"
      },
      "source": [
        "evaluate_predicrtions(data.label, [str(x) for x in data.wbs])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.09950497524876244, 6.176308815440772, 0.6194004677115716)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NiYCu3iDsjF",
        "outputId": "bdceeb68-d3ce-4d0e-87d9-bfc48d049888"
      },
      "source": [
        "evaluate_predicrtions(data.label, [str(x) for x in data.wbs_full])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.00035001750087504374, 8.778488924446222, 0.862028247540639)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wMXB_tsDse4",
        "outputId": "e6c3cabe-cc2d-4c88-f09b-22b1247cb0a9"
      },
      "source": [
        "evaluate_predicrtions(data.label, [str(x) for x in data.model])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.37551877593879696, 1.0871043552177608, 0.18982104041768535)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqIEKPdADwDI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}